{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot vectors\n",
    "\n",
    "So far, we covered continuous data encoding (floating point numbers), ordinal data encoding (usually integers), and binary categorical data encoding (survived/died, male/female, etc.).\n",
    "\n",
    "Now we'll learn how to encode data, and we'll explore categorical data resources that have more than two classes. We'll also explore the potentially harmful effects of our model improvement decisions on model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data aren't numerical\n",
    "\n",
    "Categorical data doesn't work with numbers the same way that other datatypes work with numbers. With _ordinal_ or _continuous_ (numerical) data, higher values imply an increase in amount. For example, on the Titanic, a ticket price of £30 is more money than a ticket price of £12.\n",
    "\n",
    "In contrast, categorical data has no logical order. We'll have problems if we try to encode, as numbers, categorical features that have more than two classes.\n",
    "\n",
    "For example, Port of Embarkment has three values, C (Cherbourg), Q (Queenstown), and S (Southampton). We can't replace these symbols with numbers. If we do, it would imply that one of these ports is ‘less than’ the other ports, while another is ‘greater than’ the other ports. This replacement makes no sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "\n",
    "One-hot encoding can encode categorical data in a way that avoids this problem. Each available category gets its own single column, and a given row only contains a single 1 value in the category it belongs to.\n",
    "\n",
    "For example, we can encode the port value in three columns, one for Cherbourg, one for Queenstown, one for Southampton (the exact order here has no relevance). Someone who boarded at Cherbourg would have a 1 in the Port_Cherbourg column, like this:\n",
    "\n",
    "| Port_Cherbourg | Port_Queenstown | Port_Southampton |\n",
    "| -------------- | --------------- | ---------------- |\n",
    "| 1              | 0               | 0                |\n",
    "\n",
    "Someone who boarded at Queenstown would have a 1 in the second column:\n",
    "\n",
    "| Port_Cherbourg | Port_Queenstown | Port_Southampton |\n",
    "| -------------- | --------------- | ---------------- |\n",
    "| 0              | 1               | 0                |\n",
    "\n",
    "Someone who boarded at Southampton would have a 1 in the third column\n",
    "\n",
    "| Port_Cherbourg | Port_Queenstown | Port_Southampton |\n",
    "| -------------- | --------------- | ---------------- |\n",
    "| 0              | 0               | 1                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding, data cleaning, and statistical power\n",
    "\n",
    "Before we use one-hot encoding, we should understand that its use can have positive or negative impacts on the real-world performance of a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is statistical power?\n",
    "\n",
    "Statistical power refers to the ability of a model to reliably identify real relationships between features and labels. For example, a powerful model might report a relationship between ticket price and survival rate, with a high degree of certainty. By contrast, a model with low statistical power might report a relationship with a low degree of certainty, or might not even find this relationship at all.\n",
    "\n",
    "We’ll avoid the math here, but remember that the choices we make can influence the power of our models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing data lowers statistical power\n",
    "\n",
    "We mentioned several times that data cleaning - in part - involves removal of incomplete data samples. Unfortunately, data cleaning can reduce statistical power. For example, let’s pretend that we want to predict Titanic voyage survival, given the following data:\n",
    "\n",
    "| Ticket Price | Survival |\n",
    "| ------------ | -------- |\n",
    "| £4           | 0        |\n",
    "| £8           | 0        |\n",
    "| £10          | 1        |\n",
    "| £25          | 1        |\n",
    "\n",
    "We could guess that someone with a ticket worth £15 would survive, because people with tickets that cost at least £10 all survived. If we had less data, though, this guess would become more difficult:\n",
    "\n",
    "| Ticket Price | Survival |\n",
    "| ------------ | -------- |\n",
    "| £4           | 0        |\n",
    "| £8           | 0        |\n",
    "| £25          | 1        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worthless columns lower statistical power\n",
    "\n",
    "Features that have little value can also damage statistical power, especially when the number of features (or columns) begins to approach the number of samples (or rows).\n",
    "\n",
    "For example, say that we want to be able to predict survival with the following data:\n",
    "\n",
    "| Ticket Price | Survival |\n",
    "| ------------ | -------- |\n",
    "| £4           | 0        |\n",
    "| £8           | 0        |\n",
    "| £10          | 1        |\n",
    "| £25          | 1        |\n",
    "\n",
    "We could confidently predict that someone with a Cabin A ticket would survive, because everyone with £25 tickets survived.\n",
    "\n",
    "However, now we have another feature (Cabin):\n",
    "\n",
    "| Ticket Price | Cabin | Survival |\n",
    "| ------------ | ----- | -------- |\n",
    "| £4           | A     | 0        |\n",
    "| £4           | A     | 0        |\n",
    "| £25          | B     | 1        |\n",
    "| £25          | B     | 1        |\n",
    "\n",
    "Cabin doesn't provide useful information, because it simply corresponds to the ticket price. It isn't clear if someone with a £25 Cabin A ticket would survive. Do they perish, like others from Cabin A, or survive like those with £25 tickets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding can reduce statistical power\n",
    "One-hot encoding reduces statistical power more than continuous or ordinal data, because it requires multiple columns – one for each possible categorical value. For example, if we one-hot encode the port of embarkation, we add three model inputs (C, S, and Q).\n",
    "\n",
    "A categorical variable becomes helpful if the number of categories is substantially less than the number of samples (dataset rows). A categorical variable also becomes helpful if it provides information not already available to the model through other inputs.\n",
    "\n",
    "For example, we saw that the likelihood of survival differed for people who embarked at different ports. This variation probably reflects the fact that most people at the Queenstown port had third class tickets. Therefore, embarkment probably reduces statistical power to a slight degree, without adding relevant information to our model.\n",
    "\n",
    "By contrast, Cabin likely has a strong influence on survival. This is because the lower cabins of the ship would have filled with water before the cabins closer to the upper deck of the ship filled with water. That said, the Titanic dataset contains 147 different cabins. This reduces the statistical power of our model if we include them. We might need to experiment with including or excluding Cabin data in our model, to see if Cabin data can help us."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-Beginners-Course-n5YFLC1P",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
